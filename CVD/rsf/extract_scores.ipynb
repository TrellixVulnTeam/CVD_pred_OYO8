{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specific-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pickle5\n",
    "import pickle5 as pickle\n",
    "import joblib\n",
    "\n",
    "# !pip install -U -q scikit-survival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-equipment",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "banner-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'differnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "favorite-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = 'asdf'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organized-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.9s remaining:    1.3s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    3.0s remaining:    4.1s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_cvd_all_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_cvd_all_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "# RS_y = np.array(list(tuple(zip(E_train, T_train))), dtype = [('E', bool), ('T', float)])\n",
    "# RS_test_y = np.array(list(tuple(zip(E_test, T_test))), dtype = [('E', bool), ('T', float)])\n",
    "\n",
    "#### make model\n",
    "# ##rsf = RandomSurvivalForest(n_estimators = 1, verbose = 1, n_jobs=-1)\n",
    "# ##rsf = RandomSurvivalForest(n_estimators = 30, verbose = 1, n_jobs=15)\n",
    "# rsf = RandomSurvivalForest(n_estimators = 100, verbose = 1, n_jobs=-1)\n",
    "# #rsf = RandomSurvivalForest(n_estimators = 1000, verbose = 1, n_jobs=-2)\n",
    "# rsf.fit(X_train, RS_y)\n",
    "# joblib.dump(rsf, \"joblib_model_cvd_all_rsf100n.pkl\")\n",
    "# ### make model\n",
    "\n",
    "## ALL\n",
    "rsf = joblib.load('joblib_model_cvd_all_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "# print('ALL test')\n",
    "# print(c_index_bootstrap(T_test, E_test, testPred))\n",
    "# print('ALL train')\n",
    "# print(c_index_bootstrap(T_train, E_train, trainPred))\n",
    "\n",
    "np.savetxt('RS_cvd_all.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_cvd_all.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-solution",
   "metadata": {},
   "source": [
    "# sans base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swiss-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=80)]: Done 290 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=80)]: Done 500 out of 500 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=80)]: Done 290 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=80)]: Done 500 out of 500 | elapsed:   13.7s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_cvd_sans_base_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_cvd_sans_base_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "rsf = joblib.load('joblib_model_cvd_sans_base_rsf500n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "\n",
    "np.savetxt('RS_cvd_sans_base.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_cvd_sans_base.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-anxiety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "biblical-influence",
   "metadata": {},
   "source": [
    "# lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "returning-yukon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    2.7s remaining:    3.7s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_cvd_lab_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_cvd_lab_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "rsf = joblib.load('joblib_model_cvd_lab_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "\n",
    "np.savetxt('RS_cvd_lab.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_cvd_lab.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-credits",
   "metadata": {},
   "source": [
    "# lab demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premier-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    2.9s remaining:    4.0s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_cvd_lab_demo_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_cvd_lab_demo_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "rsf = joblib.load('joblib_model_cvd_lab_demo_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "\n",
    "np.savetxt('RS_cvd_lab_demo.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_cvd_lab_demo.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-affiliate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    1.3s remaining:    1.8s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab_demo test\n",
      "(0.7593196016587828, 0.7604309417009769, 8.0711383665437e-06, 0.7558518768046909, 0.7647830531102984)\n",
      "lab_demo train\n",
      "(0.9885273199591603, 0.9884941318326813, 3.093469397644586e-09, 0.9884134089033034, 0.9885812019716707)\n"
     ]
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.datasets import load_whas500\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "from sklearn import externals\n",
    "#!pip install -U -q joblib\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def c_index_bootstrap(T, E, scores, alpha=0.05, n_bootstrap=10, random_state=None):\n",
    "  np.random.seed(random_state)\n",
    "\n",
    "  c_index = concordance_index(T, -scores, E)\n",
    "\n",
    "  stacked_arr = np.stack((T, -scores, E), axis=-1)\n",
    "  c_idx_boot = np.array([concordance_index(*resample(stacked_arr).T) for _ in range(n_bootstrap)])\n",
    "\n",
    "  c_index_boot = c_idx_boot.mean()\n",
    "  sigma2 = c_idx_boot.var()\n",
    "  CI_lower = np.quantile(c_idx_boot, alpha/2)\n",
    "  CI_upper = np.quantile(c_idx_boot, 1 - alpha/2)\n",
    "\n",
    "  return c_index, c_index_boot, sigma2, CI_lower, CI_upper\n",
    "\n",
    "E_test = np.loadtxt('../RS_cvd_lab_demo.E_test.txt')\n",
    "T_test = np.loadtxt('../RS_cvd_lab_demo.T_test.txt')\n",
    "E_train = np.loadtxt('../RS_cvd_lab_demo.E_train.txt')\n",
    "T_train = np.loadtxt('../RS_cvd_lab_demo.T_train.txt')\n",
    "with open('../RS_cvd_lab_demo_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_cvd_lab_demo_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "        \n",
    "RS_y = np.array(list(tuple(zip(E_train, T_train))), dtype = [('E', bool), ('T', float)])\n",
    "RS_test_y = np.array(list(tuple(zip(E_test, T_test))), dtype = [('E', bool), ('T', float)])\n",
    "\n",
    "\n",
    "#### make model\n",
    "##rsf = RandomSurvivalForest(n_estimators = 1, verbose = 1, n_jobs=-1)\n",
    "##rsf = RandomSurvivalForest(n_estimators = 30, verbose = 1, n_jobs=15)\n",
    "# rsf = RandomSurvivalForest(n_estimators = 100, verbose = 1, n_jobs=-1)\n",
    "#rsf = RandomSurvivalForest(n_estimators = 1000, verbose = 1, n_jobs=-2)\n",
    "# rsf.fit(X_train, RS_y)\n",
    "# joblib.dump(rsf, \"joblib_model_cvd_lab_demo_rsf100n.pkl\")\n",
    "### make model\n",
    "\n",
    "rsf = joblib.load('joblib_model_cvd_lab_demo_rsf100n.pkl')\n",
    "\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "print('lab_demo test')\n",
    "print(c_index_bootstrap(T_test, E_test, testPred))\n",
    "print('lab_demo train')\n",
    "print(c_index_bootstrap(T_train, E_train, trainPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-double",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
