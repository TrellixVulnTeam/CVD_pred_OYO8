{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadc25fe-f6dc-4d84-9fe6-dc9a5537d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pickle5\n",
    "import pickle5 as pickle\n",
    "import joblib\n",
    "\n",
    "# !pip install -U -q scikit-survival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332cb18-9e41-4f7a-b8df-5c0f37378be4",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81f51a2-0178-4c38-9b14-f19dee9c2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'differnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa6e22d-4fab-49b9-94d2-3837a0c75e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = 'asdf'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb93acf3-cda1-416d-8d27-e6994fd8beee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 86 and input n_features is 52.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-824947e0ad09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrsf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joblib_model_composite_all_rsf100n.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtestPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtestPred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrainPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/deepsurv/lib/python3.6/site-packages/sksurv/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mrisk\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cumulative_hazard_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/deepsurv/lib/python3.6/site-packages/sksurv/ensemble/forest.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, predict_fn, X)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/deepsurv/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.9/envs/deepsurv/lib/python3.6/site-packages/sksurv/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    357\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                              \u001b[0;34m\"input n_features is %s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 86 and input n_features is 52."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_composite_all_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_composite_all_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "# RS_y = np.array(list(tuple(zip(E_train, T_train))), dtype = [('E', bool), ('T', float)])\n",
    "# RS_test_y = np.array(list(tuple(zip(E_test, T_test))), dtype = [('E', bool), ('T', float)])\n",
    "\n",
    "#### make model\n",
    "# ##rsf = RandomSurvivalForest(n_estimators = 1, verbose = 1, n_jobs=-1)\n",
    "# ##rsf = RandomSurvivalForest(n_estimators = 30, verbose = 1, n_jobs=15)\n",
    "# rsf = RandomSurvivalForest(n_estimators = 100, verbose = 1, n_jobs=-1)\n",
    "# #rsf = RandomSurvivalForest(n_estimators = 1000, verbose = 1, n_jobs=-2)\n",
    "# rsf.fit(X_train, RS_y)\n",
    "# joblib.dump(rsf, \"joblib_model_composite_all_rsf100n.pkl\")\n",
    "# ### make model\n",
    "\n",
    "## ALL\n",
    "rsf = joblib.load('joblib_model_composite_all_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "# print('ALL test')\n",
    "# print(c_index_bootstrap(T_test, E_test, testPred))\n",
    "# print('ALL train')\n",
    "# print(c_index_bootstrap(T_train, E_train, trainPred))\n",
    "\n",
    "np.savetxt('RS_composite_all.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_composite_all.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4264b8a-016c-4d79-8817-af4b9b2b2529",
   "metadata": {},
   "source": [
    "# sans base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17886a44-e08a-4af2-86b2-800789825193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_composite_sans_base_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_composite_sans_base_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "rsf = joblib.load('joblib_model_composite_sans_base_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "\n",
    "np.savetxt('RS_composite_sans_base.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_composite_sans_base.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96fb8d-df4e-4127-849c-78f94b5bcdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d596acc4-162b-49e0-b39c-eb064b9166f4",
   "metadata": {},
   "source": [
    "# lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28357c5-38ac-4960-b1c1-d83ca89f3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_composite_lab_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_composite_lab_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "rsf = joblib.load('joblib_model_composite_lab_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "\n",
    "np.savetxt('RS_composite_lab.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_composite_lab.pred_score.rsf.test.txt',testPred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f5433-a369-4343-b9f5-db70706bbb28",
   "metadata": {},
   "source": [
    "# lab demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59593fa0-5e0b-41ce-8fc6-18f8bf386a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=80)]: Using backend ThreadingBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.7s remaining:    0.9s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../RS_composite_lab_demo_X_TRAIN', 'rb') as pickle_file:\n",
    "    X_train = pickle.load(pickle_file)\n",
    "    with open('../RS_composite_lab_demo_X_test', 'rb') as pickle_file:\n",
    "        X_test = pickle.load(pickle_file)\n",
    "\n",
    "rsf = joblib.load('joblib_model_composite_lab_demo_rsf100n.pkl')\n",
    "\n",
    "testPred = pd.Series(rsf.predict(X_test))\n",
    "testPred\n",
    "trainPred = pd.Series(rsf.predict(X_train))\n",
    "\n",
    "np.savetxt('RS_composite_lab_demo.pred_score.rsf.train.txt',trainPred)\n",
    "np.savetxt('RS_composite_lab_demo.pred_score.rsf.test.txt',testPred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
